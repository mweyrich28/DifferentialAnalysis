\documentclass[12pt]{article}
\usepackage{paper,math}
\usepackage[margin=1in]{geometry}
\addbibresource{references.bib}

\title{Genomorientierte Bioinformatik \\ - \\ Differential Analysis}
\author{Malte Weyrich}
\date{\today}
% Conditionally display thoughts (hide by switching to `\boolfalse`)
% \booltrue{INCLUDECOMMENTS}
\newcommand{\malte}[1]{\coauthorComment[Malte]{#1}}

\begin{document}

% Title Page -------------------------------------------------------------------
\maketitle
\begin{abstract}
\textit{Alternatives Splei\ss ing} ist ein fundamentaler zellulärer Mechanismus  mit 
gro\ss en Einfluss auf regulatorische Prozesse und Genprodukte.
Dabei werden die \textit{Exons} eines Transkripts teilweise übersprungen oder neu angeordnet. 
Verantwortlich für diesen Prozess ist das \textit{Splei\ss osom}. 
Die Identifizierung von \textit{differentiellen Spleiß-Events}, also Unterschieden im \textit{Spleißverhalten} zwischen verschiedenen Bedingungen,
ist entscheidend für das Verständnis von Genregulation und Krankheitsmechanismen.
Im Folgenden wird ein Programm zur Quantifizierung von \textit{Skipped Exon Events} vorgestellt und
dessen Ergebnisse mit einem Hypothesen Test evaluiert. 
Es wurde auf zehn \textit{bam}-Dateien ausgeführt mit \textit{annotation\_b37.gtf}
als Referenzgenom.
Zusätzlich werden die Resultate mit einem bereist publizierten Tool (\textit{\textbf{DEXSeq}} aus \cite{anders2012detecting}) verglichen.

\end{abstract}

\newpage

\tableofcontents

\newpage

% Paper ------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\section{Berechnung der Percent Spliced-In Werte}
\subsection{Definition}\label{sec:Definition}
\textit{Percent Spliced-In (PSI)} Werte werden in der Bioinformatik genutzt, um die 
Evidenz von \textit{Skipped Exon Events} anhand von beobachteten Daten darzustellen. 
Die \textit{Skipped Exon Events} entstehen durch \textit{Alternatives Splei\ss en} und beeinflussen ma\ss geblich das Proteinendprodukt
eines \textit{Gens}.
Die Expression von Transkripten kann mittels \textit{RNAseq} untersucht werden, bei dem die Sequenzen der
vorliegenden Transkripte sequenziert werden.
Somit entstehen Milliarden von \textit{Reads}, welche 
mit der Hilfe von \textit{Software} zurück auf das \textit{Referenz Genom} projiziert werden können.
Anschlie\ss end werden die \textit{Reads} annotiert, das hei\ss t es wird geschaut, von 
welchen Transkripten die \textit{Reads} stammen. 
Der \textit{PSI} Wert wird dann mittels \textit{Inclusion Read Counts (\textbf{IRC})} und \textit{Exclusion Read Counts (\textbf{ERC})} berechnet werden:

\[
    PSI := \frac{IRC}{IRC + ERC}
.\]
Sei $G$ ein \textit{Gen}  mit Transkripten $WT$ und $SV$. 
Zudem sei $se$ eine, durch die Annotation implizierte, übersprungene Region in $WT$, 
für die der \textit{PSI} Wert berechnet werden soll.
Wenn $R$ die Menge an aligniernten \textit{Read Pairs} auf $G$ ist,
dann ist $I \subseteq R$ die Menge an alignierten \textit{Read Pairs} auf $se$ und somit 
\[
   IRC_{se} := \left|I\right|
.\]
Die \textit{Exclusion Reads} $E \subseteq R$ sind genau die \textit{Read Pairs},
welche nicht auf $se$ \textit{gemapped}  werden können.

\[
   ERC_{se} := \left|E\right|
.\]
Ein \textit{PSI} Wert von 1 würde beispielsweise bedeuten, dass die Region $se$ in den
beobachteten Transkripten eines \textit{Gens} überwiegend inkludiert wurde
(also nicht durch das \textit{Splei\ss osom} heraus gesplie\ss t wurde), während ein Wert von 0
auf ein vermehrtes Ausschlie\ss en von $se$ hindeuten würde.


\subsection{Programm Logik}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.99\textwidth]{./figures/PSI-Mapping.png}
    \caption{Programmlogik zur Berechnung der \textit{IRC} und \textit{ERC counts} pro \textit{Skipped Exon Event}.
    In dem Beispiel hätte das übersprungene Exon von \textbf{G1} einen \textit{PSI} Wert von 0.75.
    Die Abbildung wurde mit \cite{biorender} erstellt.}

    \label{fig:PSI-Mapping-png}
\end{figure}

Der \textit{JAR} werden eine \textit{bam}- und ein \textit{GTF}-Datei übergeben.
Zudem muss eine Ausgabedatei Spezifiziert werden:
\begin{verbatim*}
    java -jar psi.jar -bam <bam> 
                      -gtf <gtf> 
                      -o <ausgabe.psi>
\end{verbatim*}

Die \textit{JAR} liest zunächst die \textit{GTF}-Datei ein und speichert alle \textit{Gene} und deren annotierte
\textit{Transkripte} ab. 
Dabei enthält jedes \textit{Transkript} jeweils dessen \textit{Exons} \textbf{und} \textit{Coding DNA Sequences (CDS)}.
Gleichzeitig wird die \textit{bam}-Datei mittels der \textit{samtools library} decodiert und abgespeichert.
Nach der Einleseroutine kann das Programm in vier Schritte eingeteilt werden (siehe Abbildung \ref{fig:PSI-Mapping-png}):

\begin{itemize}
    \item[\textbf{I.}] \textbf{MAP READS TO EXONS}

        Die \textit{Read Pair} Koordinaten werden mit den \textit{\textbf{Exon}} Koordinaten der Transkripte abgeglichen. 
        Sobald mindestens ein \textit{Read Pair} auf ein \textit{Gen} \textit{mapped}, wird das \textit{Gen}
        in einer \textit{ArrayList<Gene> \textbf{mappedGenes}} abgelegt.
        Die Kriterien für einen validen \textit{Read} wurden bereits im letzten Report geklärt. 
        Es werden nur \textit{Reads} in \textit{mappedGenes} hinzugefügt, wenn sie auf genau ein einziges \textit{Transkript}
        passen.

    \item[\textbf{II.}] \textbf{COLLECT READS AND GAPS PER GENE}

        Für jedes der Gene in \textbf{\textit{mappedGenes}} werden nun zwei Intervallbäume $A, B$ erstellt.
        Baum $A$ beinhaltet alle \textit{AlignmentBlocks} der zum Gen zugeteilten \textit{Read Pairs},
        während Baum $B$ die Lücken zwischen einzelnen \textit{AlignmentBlocks} und zwischen
        den \textit{Forward} und \textit{Reverse Reads} abspeichert.

    \item[\textbf{III.}] \textbf{DETERMINE EXON SKIPPING EVENTS USING CDS}

        Im nächsten Schritt wird über alle Gene aus \textbf{\textit{mappedGenes}} iteriert.
        Für jedes einzelne Gen werden alle \textit{Skipped Exon Events} mittels der
        \textit{CDS} des Gens berechnet. Dabei wird dieselbe Logik wie in 
        Report 1 verwendet.

    \item[\textbf{IV.}] \textbf{QUERY SKIPPED CDS IN INTERVALTREE}

        Für jede \textit{CDS} werden nun dessen Intervalle in den Bäumen $A, B$ abgefragt und die
        \textit{Read IDs} gezählt.
        \[
        IRC := |\left\{\textit{A.\textbf{getIntervalsSpannedBy}(CDS.getStart(), CDS.getStop())}\right\}|
        \]
        \[
        ERC := |\left\{\textit{B.\textbf{getIntervalsSpanning}(CDS.getStart(), CDS.getStop())}\right\}|
        \]
        Dabei werden für $IRC$ \textbf{Intervalle} in $A$ betrachtet, \textbf{die von der \textit{CDS} überspannt werden} \\
        ($\equiv$ "\textit{Reads} die innerhalb der \textit{CDS} liegen") und für 
        $ERC$ werden \textbf{Intervalle} in $B$ gesucht, \textbf{die die \textit{CDS} überspannen} 
        ($\equiv$ "Intervalle, die die \textit{CDS} beinhalten").
\end{itemize}
\newpage

Die \textit{PSI} Werte werden in die Ausgabedatei mit folgendem Format geschrieben:
\begin{verbatim*}
   Gene ID            cdsStart-cdsStop   IRC   ERC  Total  PSI
   ENSG00000165623.5  13275735-13275801  25    13   38     0.65
   ...                ...                ...   ...  ...    ...
\end{verbatim*}

\section{Hypothesen Test}
Wir wollen untersuchen, ob der Prozess des \textit{Alternativen Splei\ss ens} anhand von 
\textit{Exon Skipping Events} ($\mathbf{\Psi}$) rein zufällig stattfindet, oder von regulatorischen 
Mechanismen gesteuert wird. 

\begin{itemize}
    \item \textbf{H\textsubscript{0}} := \textit{Exon Skipping Events} finden zufällig statt.
    \item \textbf{H\textsubscript{1}} := \textit{Exon Skipping Events} sind nicht reiner Zufall.
\end{itemize}
Dafür nehmen wir an, dass die Anzahl an \textit{IRC} Binomial Verteilt ist:

\[
P(i,N|p) = \binom{N}{i}p^{i}(1-p)^{N-i}
.\]
Hierbei beschreibt $p$ die Wahrscheinlichkeit, dass ein einzelnes \textit{Exon} als \textit{Inclusion Read} klassifiziert wird,
während $N$ die Anzahl an \textit{Reads} darstellt, die für das momentane \textit{Exon} einen Informationsgehalt haben.
Zudem gehen wir davon aus, dass jedes Transkript mindestens einen informativen \textit{Read} pro Exon hat.

Für den Test wurden die zehn Ausgabedateien der \textit{JAR} in zwei Gruppen unterteilt (siehe Tabelle \ref{tab:einteilung}):

\begin{table}[htpb]
    \centering
    \caption{Einteilung der Samples in zwei Gruppen}
    \label{tab:einteilung}
\begin{tabular}{|l||c|c|c|c|c|c|c|c|c|c|} \hline
     Ausgabedatei $i$   & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\\hline
     Gruppe $g_{i}$ & 1 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2 \\\hline
     IRC          &$i_{1}$&$i_{2}$&$i_{3}$&$i_{4}$&$i_{5}$&$i_{6}$&$i_{7}$&$i_{8}$&$i_{9}$&$i_{10}$  \\\hline
     Gesamt Anzahl&$N_{1}$&$N_{2}$&$N_{3}$&$N_{4}$&$N_{5}$&$N_{6}$&$N_{7}$&$N_{8}$&$N_{9}$&$N_{10}$  \\ \hline\hline
     $\mathbf{\Psi_{reduced}} \sim (p_{0})$   &$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$&$p_{0}$\\\hline
     $\mathbf{\Psi_{full}} \sim  (p_{1}, p_{2})$ &$p_{1}$&$p_{1}$&$p_{1}$&$p_{1}$&$p_{1}$&$p_{2}$&$p_{2}$&$p_{2}$&$p_{2}$&$p_{2}$\\\hline
\end{tabular}
\end{table}
\newpage

Dabei simulieren wir zwei \textit{Modellen}:
\begin{itemize}
    \item $\mathbf{\Psi_{reduced}} \sim(p_{0})$: Hat einen einzigen Parameter $p_{0}$ für alle Gruppen.
    \item $\mathbf{\Psi_{full}} \sim(p_{1}, p_{2})$: Besitzt zwei verschiedenen Parameter.
\end{itemize}
Die \textit{Likelihood} kann nun mit der \textit{Maximum Likelihood Estimation} Methode
abgeschätzt werden.
Die \textit{Log-Likelihood Funktionen} lasses sich wie folgt definieren:
\begin{itemize}
\item $\mathbf{\mathcal{L}_{reduced}}(p_{0}) := \log\Big(\prod_{j = 1}^{10}P(i_{j},N_{j}|p_{0})\Big)$
\item $\mathbf{\mathcal{L}_{full}}(p_{1}, p_{2}) := \log\Big(\prod_{j = 1}^{10}P(i_{j},N_{j}|p_{g_{j}})\Big)$
\end{itemize}
Indem man die jeweilige Ableitung von $\mathbf{\mathcal{L}}$ gleich null setzt, 
erhält man die \textit{MLE} Schätzer $\hat p_{0}$ und $\hat p_{1}, \hat p_{2}$:
\begin{align*}
    \mathbf{\mathcal{L}}(\hat p_{0})  &= \log\Bigg( \prod_{j=1}^{10} \binom{N}{i_{j}}p_{0}^{i_{j}}(1-p_{0})^{N_{j}-i_{j}}  \Bigg)\\
    \mathbf{\mathcal{L}}(\hat p_{0})  &= \sum_{j=i}^{10} \log\Bigg(\binom{N_{j}}{i_{j}}\Bigg) + \log(p_{0})\sum_{j=1}^{10} i_{j} + \log(1-p_{0}) \sum_{j=1}^{10} (N_{j} - i_{j}) \\
    \mathbf{\mathcal{L}}'(\hat p_{0}) &= \frac{\sum_{j=1}^{10} i_{j}}{p_{0}} - \frac{\sum_{j=1}^{10} (N_{j} - i_{j})}{1-p_{0}} \\
                   0 &= \frac{\sum_{j=1}^{10} i_{j}}{p_{0}} - \frac{\sum_{j=1}^{10} (N_{j} - i_{j})}{1-p_{0}} \\
                   \hat p_{0} &= \frac{\sum_{j=1}^{10} i_{j}}{\sum_{j=1}^{10} N_{j}} \\ 
                              & \\
    \mathbf{\mathcal{L}}(\hat p_{1}, \hat p_{2})  &= \log\Bigg( \prod_{j=1}^{10} \binom{N}{i_{j}}p_{g_{i}}^{i_{j}}(1-p_{g_{i}})^{N_{j}-i_{j}}  \Bigg)\\
    % \mathbf{\mathcal{L}}(\hat p_{1}, \hat p_{2}) &= \sum_{j \in Gruppe_{1}} \log\Bigg(\binom{N_{j}}{i_{j}}\Bigg) + \log(p_{1})\sum_{j \in Gruppe_{1}} i_{j} + \log(1-p_{1}) \sum_{j \in Gruppe_{1}} (N_{j} - i_{j}) \\ 
    %                                              &\hspace{6mm} + \sum_{j \in Gruppe_{2}} \log\Bigg(\binom{N_{j}}{i_{j}}\Bigg) + \log(p_{2})\sum_{j \in Gruppe_{2}} i_{j} + \log(1-p_{2}) \sum_{j \in Gruppe_{2}} (N_{j} - i_{j}) \\ 
    \iff \mathbf{\mathcal{L}}(\hat p_{1}, \hat p_{2}) &= \mathbf{\mathcal{L}_{Gruppe_{1}}}(p_{1}) + \mathbf{\mathcal{L}_{Gruppe_{2}}}(p_{2}) \\
    \mathbf{\mathcal{L}_{Gruppe_{1}}}'(\hat p_{1}) &= \frac{\sum_{j \in Gruppe_{1}}i_{j}}{p_{1}} - \frac{\sum_{j \in Gruppe_{1}} (N_{j} - i_{j})}{1-p_{1}} \\
    \iff \hat p_{1} &= \frac{\sum_{j \in Gruppe_{1}} i_{j}}{\sum_{j \in Gruppe_{1}} N_{j}}\\
    \mathbf{\mathcal{L}_{Gruppe_{2}}}'(\hat p_{2}) &= \dots \\
    \hat p_{2} &= \frac{\sum_{j \in Gruppe_{2}} i_{j}}{\sum_{j \in Gruppe_{2}} N_{j}}\\
\end{align*}

Die \textit{Likelihood Schätzer} können nun verwendet werde, um $\mathbf{\mathcal{L}_{reduced}}(\hat p_{0})$ und $\mathbf{\mathcal{L}_{full}}(\hat p_{1}, \hat p_{2})$ zu 
berechnen. Zudem bestimmen wir jeweils die \textit{Likelihood Ratio Statistik (LRS)}:
\[
    LRS := -2 \log\Big(\frac{\mathcal{L}_{reduced}}{\mathcal{L}_{full}}\Big)
.\]

Dabei gilt: 
\[
    LRS \sim \chi^{2}
.\]
Somit können wir für jeden der berechneten \textit{PSI} Werte einen $p$ Wert berechnen. 
Zudem wurde die \textit{Benjamini Hochburg} Methode (\cite{bh_correction}) verwendet, um die $p$ Werte 
anzupassen, da multiple Hypothesen Tests durchgeführt wurden.

Das \textit{R} Skript \textit{LRS.R} implementiert die Berechnung der \textit{LRS} und $p$
Werte und schreibt die Resultate in eine Ausgabedatei:

\begin{verbatim*}
gene  exon        p0    p1    p2      llreduced    llfull   lrs  pvalue padj
id    start-stop  0.64  0.64  0.65  -25.86       -25.82  0.07 0.78   0.9
...   ...         ...   ...   ...   ...          ...     ...  ...    ...
    
\end{verbatim*}

\section{Komplexität und Korrektheit}\label{sec:Komplexität und Korrektheit}
\subsection{Komplexität}\label{sec:Komplexität}
Das entwickelte Java Programm benutzt für das Einlesen der \textit{GTF}-Datei, dem Bestimmen
der \textit{Exon Skipping Events} und dem \textit{Mapping} der \textit{Reads} dieselbe Komplexität
wie die Programme aus Report 1 und 3.
Das einzige was an zusätzlichem Aufwand anfällt ist die Erstellung der Intervallbäume pro Gen (A) und das 
anschlie\ss ende Zählen der \textit{IRC} und \textit{ERC} (B).
\begin{itemize}
    \item[\textbf{(A)}] \textbf{Erstellen der Intervallbäume:} 

        Sei $\tilde G$ die Menge aller \textit{Gene} aus der vorliegenden \textit{Annotation} und
        $\tilde R$ die Menge aller \textit{Reads} aus dem Sequenzierexperiment.
        Dann ist $G \subseteq \tilde G$ die Teilmenge an \textit{Genen}, auf 
        welche es ein \textit{Mapping} von \textit{Reads} gibt.
        Jedes \textit{Gen} $g_{i} \in  G$ hat also eine Teilmenge $R_{i}$ an
        alignierten \textit{Reads} aus $\tilde R$.
        Für jedes Gen $g_{i}$ werden alle zugehörigen \textit{Reads} $R_{g}$
        in die Intervallbäume $A$ und $B$ eingefügt.
        Das Einfügen in einen Intervallbaum hat ein logarithmisches 
        Kostenma\ss : $\mathcal{O}(\log n)$, wobei $n$ die Gesamtanzahl an
        Intervallen ist, welche sich bereits in dem Baum befinden.
        Für das konsekutive Einfügen von \textit{Reads} aus $R_{g}$ in $A$ ergibt sich folgende, von 
        oben abgeschätzte Laufzeit:
        \begin{align*}
            1  + \log(1) + \log(2) + \dots + \log(|R_{g}| + k) &< \sum^{|R_{g}| + k} \log (|R_{g}| + k) \\
                                                               &\in \mathcal{O}\Big((|R_{g}| + k) \cdot \log(|R_{g}| + k)\Big)
        \end{align*}
        Bei $k$ handelt es sich um eine Konstante, welche die Anzahl an Fällen beschreibt,
        wo ein einzelner \textit{Read} aus $R_{g}$ aus mehreren \textit{AlignmentBlocks} besteht.

        Das gleiche gilt für die \textit{Gaps}, welche in den zweiten Intervallbaum eingefügt werden:
        \begin{align*}
        1  + \log(1) + \log(2) + \dots + \log(R_{i}/2 + c) &< \sum^{|R_{g}|/2 + c} \log (|R_{g}|/2 + c) \\
                                                           &\in \mathcal{O}\Big((|R_{g}|/2 +c) \cdot \log(|R_{g}|/2 + c)\Big) \\
                                                           &\in \mathcal{O}\Big((|R_{g}| + c) \cdot \log(|R_{g}| + c)\Big)
        \end{align*}
        Da es sich um \textit{paired end} Daten handelt (Abbildung \ref{fig:PSI-Mapping-png}), gibt es zwischen nicht überlappenden \textit{Read Pairs} einen \textit{Gap}
        (also insgesamt $\le |R_{g}|/2$) und zusätzlich $c$ viele \textit{Gaps} zwischen den jeweiligen
        \textit{AlignmentBlocks} der \textit{Reads} (\textbf{hierbei ist} $\mathbf{c == k}$, \textbf{da durch jeden zusätzlichen \textit{AlignmentBlock} 
        in einem \textit{Read} auch ein zusätzlicher \textit{Gap} im \textit{Read} existiert}).

        Da wir insgesamt $|G|$ viele Gene haben also:
        \begin{align*}
            \mathcal{O}\Bigg(|G| \cdot \Big((|R_{\tilde g}| + k) \cdot \log(|R_{\tilde g}| + k) &+ (|R_{\tilde g}|+c) \cdot \log(|R_{\tilde g}| + c)\Big)\Bigg)\\
            \in \mathcal{O}\Bigg(|G| \cdot \Big(2 \cdot (|R_{\tilde g}| + k) \cdot \log(|R_{\tilde g}| &+ k)\Big)\Bigg)\\
            \in \mathcal{O}\Bigg(|G| \cdot \Big((|R_{\tilde g}| + k) \cdot \log(|R_{\tilde g}| &+ k)\Big)\Bigg)\\
        \end{align*}
        , wobei 
        \[
            \tilde g := \operatornamewithlimits\forall_{\substack{R_{g} \in R,\\R_{g} \not =  R_{\tilde g}}} R_{g} \le R_{\tilde g}
        \]
        das Gen mit den meisten alignierten \textit{Reads} ist.

    \item[\textbf{(B)}] \textbf{Ermittlung der \textit{IRC} und \textit{ERC:}}

        Eine Suchoperation in einem Intervallbaum hat ebenfalls eine Komplexität von $\mathcal{O}(\log n)$.
        Nach \textbf{Schritt (A)} befinden sich in den Bäumen $A,B$ von einem Gen $g \in G$ genau $|R_{i}|$
        und $|R_{i}|/2 + c$ viele \textit{Reads}.
        Jedes $g \in G$ besitzt $e_{g}$ viele \textit{Exon Skipping Events}. So muss 
        $|e_{g}|$ oft in jeweils beiden Bäumen eine Suche getätigt werden.
        Pro Gen also:
        \[
            |e_{g}| \cdot \log(R_{\tilde g}) + |e_{g}| \cdot \log(R_{\tilde g}/2 + c) = |e_{g}| \cdot  (\log(R_{\tilde g}) + \log(R_{\tilde g} + c) \in \mathcal{O}\Big(|e_{g}| \cdot \log(R_{\tilde g} + c)\Big)
        .\]
\end{itemize}
\subsection{Korrektheit}\label{sec:Korrektheit}
Der Ansatz mit den Intervallbäumen ist Korrekt. In den Intervallbäumen werden nur \textit{Reads} abgespeichert, die genau auf
ein \textit{Transkript} passen. Somit werden schon mal alle \textit{Reads} ohne eindeutigen Informationsgehalt 
ignoriert. Zusätzlich werden zu jeder hinzugefügten Region (in beiden Bäumen), die \textit{Ursprungs ID}
(in diesem Fall die Transkript ID) und die \textit{Read ID} gespeichert. 
Da der Intervallbaum korrekt implementiert ist, liefert diese entweder alle 
Intervalle, die von der übersprungenen \textit{CDS} beinhaltet werden (Baum $A$),
oder alle \textit{Gaps}, welche die \textit{CDS} überspannen (Baum $B$).
Die Anzahl an einzigartigen \textit{Read IDs} beider Abfragen ergibt dann die 
jeweiligen \textit{IRC} und \textit{ERC}.
Der einzige Sonderfall ergibt sich, wenn eine Region $r$ aus dem Baum $B$ dieselbe
\textit{Transkript ID} hat wie das der übersprungenen \textit{CDS}. 
In diesem Fall impliziert $r$ dann keinen \textit{ERC} sonder einen \textit{IRC}, 
denn $r$ wurde schlie\ss lich eindeutig auf das \textit{Transkript} der \textit{CDS}
aligniert.
\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/EdgeCase.png}
    \caption{Sonderfall bei der Berechnung von \textit{ERC}. Der \textit{Read} passt hier nur auf \textbf{T1} und obwohl sich die übersprungene \textit{CDS} in der Lücke zwischen
    \textit{Forward} und \textit{Reverse Read} befindet, zählt dieser \textit{Read} als \textit{IRC}, denn er kann nur durch \textbf{T1} entstanden sein.
Die Abbildung wurde mit \cite{biorender} erstellt}
    \label{fig:-figures-EdgeCase-png}
\end{figure}
\newpage
\section{Ergebnisse}\label{sec:Ergebnisse}
\subsection{\textit{Read} Abdeckung}\label{sec:-textit-Read-Abdeckung}
\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.7\textwidth]{./plots/trees.png}
    \caption{Verteilung der Anzahl von abgespeicherten Intervalle der Bäume $A$, $B$ pro Gen.
    Dabei beinhaltet Typ $A$ jeweils alle abdeckenden \textit{AlignmentBlocks}/\textit{Reads} für ein Gen und $B$ die \textit{Gaps} zwischen
    \textit{AlignmentBlocks} eines \textit{Reads} und zwischen \textit{Forward} und \textit{Reverse Read}.}
    \label{fig:-plots-trees-png}
\end{figure}
\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.8\textwidth]{./plots/genetrees.png}
    \caption{Anzahl an Intervallen pro Gen pro Intervallbaum.}
    \label{fig:-plots-genetrees-png}
\end{figure}
Wie bereits in Abschnitt \ref{sec:Komplexität} beschrieben, sollte die Anzahl an Intervallen pro Gen in Baum $B$ nicht 
grö\ss er als in $A$ sein. Die Verteilungen in Abbildung \ref{fig:-plots-trees-png} lassen dies bereits vermuten, da die Verteilung der Werte für 
$B$ ungefähr um den Faktor $0.5$ nach links verschoben ist.
Ebenfalls zusehen ist, dass die Hälfte aller Gene mindesten 308 alignierte \textit{AlignmentBlocks}.

In Abbildung \ref{fig:-plots-genetrees-png} ist es deutlicher zu erkennen, 
dass die Mengen $|R_{g}|$ in Bäumen $A$ immer grö\ss er ist als die Anzahl an
\textit{Gaps} in $B$.
Ebenfalls zu sehen ist , dass es einige Gene mit vielen überlappenden
\textit{Forward} und \textit{Reverse Reads} gibt. Dies ist der Fall wenn Baum $A$ mehr als doppelt so viele 
Intervalle beinhaltet als Baum $B$.





\subsection{PSI Werte}
\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.7\textwidth]{./plots/neg_log10_padj_by_chromosome.png}
    \caption{Angepasste P-Werte nach Chromosomen. Die Rote Linie kennzeichnet das transformierte Signifikanzniveau von $\mathbf{\alpha = 0.05}$.
    Alle Punkte über der Indikatorlinie sind als signifikant zu interpretieren. Insgesamt wurden 232 \textit{Exon Skipping Events} entdeckt.}
    \label{fig:neg_log10_padj_by_chromosome-png}
\end{figure}

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.7\textwidth]{./plots/prob.png}
    \caption{Verteilung der $p_{0}$, $p_{1}$ und $p_{2}$ Werte für das $\mathbf{\Psi_{reduced}}$ und $\mathbf{\Psi_{full}}$ Modell.}
    \label{fig:prob-png}
\end{figure}

In Abbildung \ref{fig:neg_log10_padj_by_chromosome-png} wurden die korrigierten, logarithmierten P-Werte nach chromosomaler Position
aufgetragen. Der Gro\ss teil an signifikanten Werten liegt in den 
Chromosomen 1-9, was darauf hindeuten könnte, dass die \textit{Exon Inklusion} innerhalb
dieser Regionen durch regulatorische Elemente wie z.B. \textit{Promotoren}, \textit{Enhancern} oder \textit{Silencer}
gesteuert wird. Der Trend könnte ebenfalls implizieren, dass die Gene auf denn ersten 
neun Chromosomen anfälliger für Alternatives Splei\ss en sind, da sie beispielsweise für 
wichtige Splei\ss varianten codieren.

Abbildung \ref{fig:prob-png} zeigt die Verteilung der Wahrscheinlichkeiten $p_{0}, p_{1}$ und $p_{2}$, welche 
jeweils mit den \textit{Likelihood Schätzern} pro Event errechnet worden sind. Hier ist bereits 
ein Unterschied zwischen dem $\mathbf{\Psi_{reduced} \sim }(p_{0})$ und dem $\mathbf{\Psi_{full} \sim} (p_{1}, p_{2})$
zu sehen, da die 
da die $p_{0}$-Verteilung eine einzelne, konzentrierte Wahrscheinlichkeitsverteilung zeigt,
während das vollständige Modell zwei separate Verteilungen ($p_{1}$ und $p_{2}$) mit unterschiedlichen
Maxima aufweist.



\subsection{Vergleich mit DEXSeq}
Um unsere Ergebnisse mit \textit{DEXSeq} zu vergleichen, haben wir die selben zehn
\textit{bam}-Dateien für das Tool aufbereitet und als Eingabe verwendet.
Die resultierenden Exons wurden zurück auf die von uns verwendete Annotationsdatei 
projiziert, um sie mit den Ergebnissen unseres Modells vergleichen zu können.
Für beide Tools wurde in Abbildung \ref{fig:roc_comparison-png} die
\textit{"Receiver Operating Characteristics" (ROC)} Kurve aufgetragen.


\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.6\textwidth]{./plots/roc_comparison.png}
    \caption{ROC Kurven Vergleich mit \textit{DEXseq}.}
    \label{fig:roc_comparison-png}
\end{figure}

Die \textit{ROC-Kurven} zeigen einen deutlichen Leistungsunterschied zwischen 
unserem \textit{JAR LRS} Modell und \textit{DEXSeq}. Unser Modell erreicht einen \textit{AUC}-Wert von $0.855$, während
\textit{DEXSeq} einen niedrigeren \textit{AUC}-Wert von $0.677$ aufweist (kaum besser als ein
Zufälliges Modell mit \textit{AUC} = 0.5).
Dies deutet auf eine überlegene Diskriminierungsfähigkeit des \textit{JAR LRS} Modells hin.
Der steilere Anstieg der roten Kurve im linken Bereich des Diagramm bedeutet,
dass unser Modell eine höhere \textit{True Positive Rate} bei einer niedrigeren \textit{False Positive Rate} erreicht 
- eine wichtige Eigenschaft für die praktische Anwendung, da sie auf
eine bessere Fähigkeit hinweist, tatsächliche differentielle Spleiß-Events zu erkennen,
während gleichzeitig weniger falsch-positive Ergebnisse produziert werden.

\subsection{Laufzeit}
% ------------------------------------------------------------------------------

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.8\textwidth]{./plots/time.png}
    \caption{Durchschnittliche Laufzeit der \textit{JAR} auf allen Dateien nach zehnfacher Ausführung auf \textit{AMD Ryzen 7 PRO 4750U with Radeon Graphics (16) @ 1.700GHz}.}
    \label{fig:-plots-time-png}
\end{figure}

Die Laufzeiten in Abbildung \ref{fig:-plots-time-png} sind alle knapp über einer Sekunde. Das
liegt aber vor allem daran, dass die \textit{GTF}-Datei für diese Aufgabe manuell überarbeitet wurde,
sodass jedes Gen höchstens zwei Transkripte besitzt. Dadurch ist die gekürzte Version nur
$24MB$ gro\ss . Das Einlesen der \textit{GTF}- und das Prozessieren der \textit{bam}-Dateien
nimmt am meisten Zeit in Anspruch: $323ms$ für das Einlesen der \textit{Annotation} und 800ms 
für das \textit{Mapping} einer \textit{bam}-Datei auf die Gene in der \textit{GTF}.
Die Methode \textit{\textbf{getPctSplicedCounts}} ist zuständig für die: 
\begin{itemize}
    \item Identifizierung von \textit{Exon Skipping Events}
    \item Berechnung der \textit{PSI} Werte
\end{itemize}
Sie benötigt lediglich $68ms$, da es insgesamt nur $199$ Gene in \textit{mappedGenes} gab uns nur 232 \textit{Exon Skipping Events} 
durch die Annotationsdatei impliziert werden.






\newpage
% ------------------------------------------------------------------------------
\printbibliography
% ------------------------------------------------------------------------------


\end{document}
